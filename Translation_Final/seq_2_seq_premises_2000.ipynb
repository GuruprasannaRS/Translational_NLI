{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport pyarrow.parquet as pq \nimport numpy as np \n\nfrom sklearn.model_selection import train_test_split\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-08-03T14:48:37.572977Z","iopub.execute_input":"2023-08-03T14:48:37.573888Z","iopub.status.idle":"2023-08-03T14:48:38.970006Z","shell.execute_reply.started":"2023-08-03T14:48:37.573851Z","shell.execute_reply":"2023-08-03T14:48:38.968739Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n","output_type":"stream"}]},{"cell_type":"code","source":"import numpy as np\nimport tensorflow as tf \nimport random\n\ntf.random.set_seed(123)\nnp.random.seed(123)\nrandom.seed(123)","metadata":{"execution":{"iopub.status.busy":"2023-08-03T14:49:01.709685Z","iopub.execute_input":"2023-08-03T14:49:01.710053Z","iopub.status.idle":"2023-08-03T14:49:10.743935Z","shell.execute_reply.started":"2023-08-03T14:49:01.710023Z","shell.execute_reply":"2023-08-03T14:49:10.742819Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:98: UserWarning: unable to load libtensorflow_io_plugins.so: unable to open file: libtensorflow_io_plugins.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so']\ncaused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so: undefined symbol: _ZN3tsl6StatusC1EN10tensorflow5error4CodeESt17basic_string_viewIcSt11char_traitsIcEENS_14SourceLocationE']\n  warnings.warn(f\"unable to load libtensorflow_io_plugins.so: {e}\")\n/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:104: UserWarning: file system plugins are not loaded: unable to open file: libtensorflow_io.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so']\ncaused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so: undefined symbol: _ZTVN10tensorflow13GcsFileSystemE']\n  warnings.warn(f\"file system plugins are not loaded: {e}\")\n","output_type":"stream"}]},{"cell_type":"code","source":"filepath  = r'/kaggle/input/fever-nli/fr_fever-00000-of-00001-b7ec330d6224f90b.parquet'","metadata":{"execution":{"iopub.status.busy":"2023-08-03T14:49:36.268877Z","iopub.execute_input":"2023-08-03T14:49:36.270102Z","iopub.status.idle":"2023-08-03T14:49:36.275538Z","shell.execute_reply.started":"2023-08-03T14:49:36.270061Z","shell.execute_reply":"2023-08-03T14:49:36.274275Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"table = pq.ParquetDataset(filepath)\ndf = table.read().to_pandas()","metadata":{"execution":{"iopub.status.busy":"2023-08-03T14:49:39.435722Z","iopub.execute_input":"2023-08-03T14:49:39.436084Z","iopub.status.idle":"2023-08-03T14:49:39.874794Z","shell.execute_reply.started":"2023-08-03T14:49:39.436054Z","shell.execute_reply":"2023-08-03T14:49:39.873698Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"df.head(2)","metadata":{"execution":{"iopub.status.busy":"2023-08-03T14:49:44.694815Z","iopub.execute_input":"2023-08-03T14:49:44.695207Z","iopub.status.idle":"2023-08-03T14:49:44.713910Z","shell.execute_reply.started":"2023-08-03T14:49:44.695174Z","shell.execute_reply":"2023-08-03T14:49:44.712810Z"},"trusted":true},"execution_count":5,"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"                                    premise_original  \\\n0  Islam . Sizable Muslim communities are also fo...   \n1  Gemini is a 2002 Indian Tamil-language action ...   \n\n                        hypothesis_original  label  \\\n0        Islam does not have any followers.      2   \n1  Gemini is a movie that came out in 2002.      0   \n\n                                             premise  \\\n0  Des communautés musulmanes considérables se tr...   \n1  Gemini est un film d'action indien écrit et ré...   \n\n                          hypothesis  \n0         L’islam n’a pas d’adeptes.  \n1  Gemini est un film sorti en 2002.  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>premise_original</th>\n      <th>hypothesis_original</th>\n      <th>label</th>\n      <th>premise</th>\n      <th>hypothesis</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Islam . Sizable Muslim communities are also fo...</td>\n      <td>Islam does not have any followers.</td>\n      <td>2</td>\n      <td>Des communautés musulmanes considérables se tr...</td>\n      <td>L’islam n’a pas d’adeptes.</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Gemini is a 2002 Indian Tamil-language action ...</td>\n      <td>Gemini is a movie that came out in 2002.</td>\n      <td>0</td>\n      <td>Gemini est un film d'action indien écrit et ré...</td>\n      <td>Gemini est un film sorti en 2002.</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"df_trans = df.drop(columns = ['label'], axis = 1)","metadata":{"execution":{"iopub.status.busy":"2023-08-03T14:49:48.620659Z","iopub.execute_input":"2023-08-03T14:49:48.621025Z","iopub.status.idle":"2023-08-03T14:49:48.629512Z","shell.execute_reply.started":"2023-08-03T14:49:48.620995Z","shell.execute_reply":"2023-08-03T14:49:48.628403Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"df_trans.head(2)","metadata":{"execution":{"iopub.status.busy":"2023-08-03T14:49:51.450164Z","iopub.execute_input":"2023-08-03T14:49:51.450551Z","iopub.status.idle":"2023-08-03T14:49:51.462863Z","shell.execute_reply.started":"2023-08-03T14:49:51.450518Z","shell.execute_reply":"2023-08-03T14:49:51.461809Z"},"trusted":true},"execution_count":7,"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"                                    premise_original  \\\n0  Islam . Sizable Muslim communities are also fo...   \n1  Gemini is a 2002 Indian Tamil-language action ...   \n\n                        hypothesis_original  \\\n0        Islam does not have any followers.   \n1  Gemini is a movie that came out in 2002.   \n\n                                             premise  \\\n0  Des communautés musulmanes considérables se tr...   \n1  Gemini est un film d'action indien écrit et ré...   \n\n                          hypothesis  \n0         L’islam n’a pas d’adeptes.  \n1  Gemini est un film sorti en 2002.  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>premise_original</th>\n      <th>hypothesis_original</th>\n      <th>premise</th>\n      <th>hypothesis</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Islam . Sizable Muslim communities are also fo...</td>\n      <td>Islam does not have any followers.</td>\n      <td>Des communautés musulmanes considérables se tr...</td>\n      <td>L’islam n’a pas d’adeptes.</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Gemini is a 2002 Indian Tamil-language action ...</td>\n      <td>Gemini is a movie that came out in 2002.</td>\n      <td>Gemini est un film d'action indien écrit et ré...</td>\n      <td>Gemini est un film sorti en 2002.</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"english_premises = df_trans['premise_original'].values\nenglish_premises = english_premises.tolist()\nprint(english_premises[0])\nenglish_hypothesis = df_trans['hypothesis_original'].values\nenglish_hypothesis = english_hypothesis.tolist()\nprint(english_hypothesis[0])","metadata":{"execution":{"iopub.status.busy":"2023-08-03T14:49:58.966173Z","iopub.execute_input":"2023-08-03T14:49:58.966598Z","iopub.status.idle":"2023-08-03T14:49:58.974763Z","shell.execute_reply.started":"2023-08-03T14:49:58.966564Z","shell.execute_reply":"2023-08-03T14:49:58.973781Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"Islam . Sizable Muslim communities are also found in the Americas , Caucasus , China , Europe , Mainland Southeast Asia , Philippines and Russia .\nIslam does not have any followers.\n","output_type":"stream"}]},{"cell_type":"code","source":"french_premises_ref = df_trans['premise'].values\nfrench_premises_ref = french_premises_ref.tolist()\nfrench_hypothesis_ref = df_trans['hypothesis'].values\nfrench_hypothesis_ref = french_hypothesis_ref.tolist()","metadata":{"execution":{"iopub.status.busy":"2023-08-03T14:50:01.856790Z","iopub.execute_input":"2023-08-03T14:50:01.857200Z","iopub.status.idle":"2023-08-03T14:50:01.864748Z","shell.execute_reply.started":"2023-08-03T14:50:01.857169Z","shell.execute_reply":"2023-08-03T14:50:01.863590Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"import re\ndef preprocess_text(text):\n    # Step 1: Lowercasing\n    text = text.lower()\n    # Step 2: Removing special characters and punctuation\n    text = re.sub(r\"[^a-zA-Z0-9\\s]\", \"\", text)\n    # Step 3: Removing extra whitespaces\n    text = re.sub(r\"\\s+\", \" \", text).strip()\n    return text\n\n # Preprocess the input sentences\npreprocessed_english_premises = [preprocess_text(sentence) for sentence in english_premises]\n","metadata":{"execution":{"iopub.status.busy":"2023-08-03T14:50:06.469146Z","iopub.execute_input":"2023-08-03T14:50:06.469538Z","iopub.status.idle":"2023-08-03T14:50:07.580756Z","shell.execute_reply.started":"2023-08-03T14:50:06.469508Z","shell.execute_reply":"2023-08-03T14:50:07.579558Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"#Splitting the data\n\nenglish_train, english_test, french_train, french_test = train_test_split(preprocessed_english_premises, french_premises_ref, test_size=0.2, random_state=42)","metadata":{"execution":{"iopub.status.busy":"2023-08-03T14:50:12.604861Z","iopub.execute_input":"2023-08-03T14:50:12.605236Z","iopub.status.idle":"2023-08-03T14:50:12.641609Z","shell.execute_reply.started":"2023-08-03T14:50:12.605205Z","shell.execute_reply":"2023-08-03T14:50:12.640389Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"#Predicting one sentence\nimport tensorflow as tf\nfrom transformers import TFAutoModelForSeq2SeqLM, AutoTokenizer\n\n# Load pre-trained model and tokenizer for translation\nmodel_name = \"Helsinki-NLP/opus-mt-en-fr\"\ntokenizer = AutoTokenizer.from_pretrained(model_name)\nmodel = TFAutoModelForSeq2SeqLM.from_pretrained(model_name)\n\nfrench_premises = []\n\n# English sentence to be translated\n#english_sentence = \"Hello, how are you?\"\n\n# Tokenize input sentence\nfor premise in english_premises[:3]:\n    # Tokenize input sentence\n    inputs = tokenizer(premise, truncation=True, padding=True, return_tensors=\"tf\")\n\n    # Perform translation\n    outputs = model.generate(inputs[\"input_ids\"])\n    french_ids = outputs[0].numpy()\n\n    # Decode translated sentence\n    french_sentence = tokenizer.decode(french_ids, skip_special_tokens=True)\n    french_premises.append(french_sentence)\n\n# Print the translated sentences\nprint(\"English premise:\", english_premises[2])\nprint(\"French premise:\", french_premises[2])\nprint()","metadata":{"execution":{"iopub.status.busy":"2023-08-03T14:50:17.617160Z","iopub.execute_input":"2023-08-03T14:50:17.618241Z","iopub.status.idle":"2023-08-03T14:51:28.222436Z","shell.execute_reply.started":"2023-08-03T14:50:17.618202Z","shell.execute_reply":"2023-08-03T14:51:28.221475Z"},"trusted":true},"execution_count":12,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading (…)okenizer_config.json:   0%|          | 0.00/42.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0eaa6e70080b4fff8436d505d0338b59"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)lve/main/config.json:   0%|          | 0.00/1.42k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3f12bfc3d1a844c4aa662536e92385c2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)olve/main/source.spm:   0%|          | 0.00/778k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2211e85a5f7945b1a2c6ba6e6c78f631"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)olve/main/target.spm:   0%|          | 0.00/802k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d31651d797c64fd485bf9a366c4310c9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)olve/main/vocab.json:   0%|          | 0.00/1.34M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"00137937359646f09cdd5fcffc17ce7a"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/models/marian/tokenization_marian.py:194: UserWarning: Recommended: pip install sacremoses.\n  warnings.warn(\"Recommended: pip install sacremoses.\")\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Downloading tf_model.h5:   0%|          | 0.00/301M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"53e0e52f9376475c80e6f1e4bb06c2bf"}},"metadata":{}},{"name":"stderr","text":"All model checkpoint layers were used when initializing TFMarianMTModel.\n\nAll the layers of TFMarianMTModel were initialized from the model checkpoint at Helsinki-NLP/opus-mt-en-fr.\nIf your task is similar to the task the model of the checkpoint was trained on, you can already use TFMarianMTModel for predictions without further training.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Downloading (…)neration_config.json:   0%|          | 0.00/293 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ffc99d443590415b9c219f60f6ef6efd"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/generation/tf_utils.py:854: UserWarning: Using `max_length`'s default (512) to control the generation length. This behaviour is deprecated and will be removed from the config in v5 of Transformers -- we recommend using `max_new_tokens` to control the maximum length of the generation.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"English premise: Theodore John Kaczynski ( [ kəˈzɪnski ] born May 22 , 1942 ) , also known as the `` Unabomber '' , is an American serial killer , domestic terrorist , and self-professed anarchist .\nFrench premise: Theodore John Kaczynski (né le 22 mai 1942 ), également connu sous le nom d'\"Unabomber\", est un tueur en série américain, un terroriste domestique et un anarchiste autoprofessé.\n\n","output_type":"stream"}]},{"cell_type":"code","source":"from transformers import TFAutoModelForSeq2SeqLM, AutoTokenizer, AdamWeightDecay\nimport tensorflow as tf\n\nmodel_name = \"Helsinki-NLP/opus-mt-en-fr\"\ntokenizer = AutoTokenizer.from_pretrained(model_name)\n\n# Tokenize inputs and outputs\ninputs = tokenizer(english_train[:20000], truncation=True, padding=True, return_tensors=\"tf\")\noutputs = tokenizer(french_train[:20000], truncation=True, padding=True, return_tensors=\"tf\")\n\n# Create a function that will transform our dataset\ndef map_func(input_ids, masks, labels):\n    return {'input_ids': input_ids, 'attention_mask': masks}, labels\n\n# Create tf.data.Datasets\nBATCH_SIZE = 16\ntf_train_dataset = tf.data.Dataset.from_tensor_slices((inputs['input_ids'], inputs['attention_mask'], outputs['input_ids']))\ntf_train_dataset = tf_train_dataset.map(map_func).shuffle(10000).batch(BATCH_SIZE)\n\ntf_test_dataset = tf.data.Dataset.from_tensor_slices((inputs['input_ids'], inputs['attention_mask'], outputs['input_ids']))\ntf_test_dataset = tf_test_dataset.map(map_func).batch(BATCH_SIZE)\n\noptimizer = AdamWeightDecay(learning_rate=2e-5, weight_decay_rate=0.01)\n\nmodel = TFAutoModelForSeq2SeqLM.from_pretrained(model_name)\nmodel.compile(optimizer=optimizer)\nmodel.fit(tf_train_dataset, validation_data=tf_test_dataset, epochs=3)\n","metadata":{"execution":{"iopub.status.busy":"2023-08-03T14:52:36.583359Z","iopub.execute_input":"2023-08-03T14:52:36.584422Z","iopub.status.idle":"2023-08-03T15:47:03.068967Z","shell.execute_reply.started":"2023-08-03T14:52:36.584379Z","shell.execute_reply":"2023-08-03T15:47:03.067888Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/models/marian/tokenization_marian.py:194: UserWarning: Recommended: pip install sacremoses.\n  warnings.warn(\"Recommended: pip install sacremoses.\")\nAll model checkpoint layers were used when initializing TFMarianMTModel.\n\nAll the layers of TFMarianMTModel were initialized from the model checkpoint at Helsinki-NLP/opus-mt-en-fr.\nIf your task is similar to the task the model of the checkpoint was trained on, you can already use TFMarianMTModel for predictions without further training.\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1/3\n1250/1250 [==============================] - 1133s 876ms/step - loss: 1.3070 - val_loss: 0.6232\nEpoch 2/3\n1250/1250 [==============================] - 1055s 844ms/step - loss: 0.6403 - val_loss: 0.3925\nEpoch 3/3\n1250/1250 [==============================] - 1057s 845ms/step - loss: 0.4579 - val_loss: 0.2833\n","output_type":"stream"},{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"<keras.callbacks.History at 0x7d279c9eb040>"},"metadata":{}}]},{"cell_type":"code","source":"save_directory = \"/kaggle/working\"  # Specify the directory to save the model\n\n# Save the model and tokenizer\nmodel.save_pretrained(save_directory)\ntokenizer.save_pretrained(save_directory)\n\nprint(\"Model saved successfully.\")","metadata":{"execution":{"iopub.status.busy":"2023-08-03T15:51:02.910481Z","iopub.execute_input":"2023-08-03T15:51:02.910870Z","iopub.status.idle":"2023-08-03T15:51:04.377769Z","shell.execute_reply.started":"2023-08-03T15:51:02.910838Z","shell.execute_reply":"2023-08-03T15:51:04.376412Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stdout","text":"Model saved successfully.\n","output_type":"stream"}]},{"cell_type":"code","source":"#predicting the sentences\nimport tensorflow as tf\n#from transformers import TFBertModel, BertTokenizer\nfrom transformers import TFAutoModelForSeq2SeqLM, AutoTokenizer\nfrom sklearn.model_selection import train_test_split\nfrom tensorflow.keras.losses import SparseCategoricalCrossentropy\nfrom transformers import TFAutoModelForSeq2SeqLM, AutoTokenizer\nfrom tensorflow.keras.optimizers import Adam\n\n#saved_directory = \"/kaggle/working\"  # Specify the directory where the model was saved\n\n# model = TFBertModel.from_pretrained(saved_directory)\n# tokenizer = BertTokenizer.from_pretrained(saved_directory)\n\n# Load the model\nmodel = TFAutoModelForSeq2SeqLM.from_pretrained(save_directory)\n\n# Load the tokenizer\ntokenizer = AutoTokenizer.from_pretrained(save_directory)\n\nprint(\"Model and tokenizer loaded successfully.\")\nfrench_predictions = []\n\n# Function to predict French sentences\ndef predict_french_sentences(sentences):\n    # Tokenize the input sentences\n    tokenized_inputs = tokenizer(sentences, truncation=True, padding=True, return_tensors=\"tf\")\n\n    # Generate predictions\n    predicted_ids = model.generate(tokenized_inputs.input_ids)\n    #print(predicted_ids)\n    predicted_sentences = tokenizer.batch_decode(predicted_ids, skip_special_tokens=True)\n\n    return predicted_sentences\n\n# Example usage\nfor i in range(1000):\n    english_sentence = english_test[1000+i]\n    predicted_french_sentence = predict_french_sentences([english_sentence])\n    french_predictions.append(predicted_french_sentence[0])\n    if i % 50 == 0:\n        print(f'processsed french premises', i)\n","metadata":{"execution":{"iopub.status.busy":"2023-08-03T15:55:54.838221Z","iopub.execute_input":"2023-08-03T15:55:54.838697Z","iopub.status.idle":"2023-08-03T23:16:36.484827Z","shell.execute_reply.started":"2023-08-03T15:55:54.838639Z","shell.execute_reply":"2023-08-03T23:16:36.483713Z"},"trusted":true},"execution_count":24,"outputs":[{"name":"stderr","text":"All model checkpoint layers were used when initializing TFMarianMTModel.\n\nAll the layers of TFMarianMTModel were initialized from the model checkpoint at /kaggle/working.\nIf your task is similar to the task the model of the checkpoint was trained on, you can already use TFMarianMTModel for predictions without further training.\n","output_type":"stream"},{"name":"stdout","text":"Model and tokenizer loaded successfully.\nprocesssed french premises 0\nprocesssed french premises 50\nprocesssed french premises 100\nprocesssed french premises 150\nprocesssed french premises 200\nprocesssed french premises 250\nprocesssed french premises 300\nprocesssed french premises 350\nprocesssed french premises 400\nprocesssed french premises 450\nprocesssed french premises 500\nprocesssed french premises 550\nprocesssed french premises 600\nprocesssed french premises 650\nprocesssed french premises 700\nprocesssed french premises 750\nprocesssed french premises 800\nprocesssed french premises 850\nprocesssed french premises 900\nprocesssed french premises 950\n","output_type":"stream"}]},{"cell_type":"code","source":"import pandas as pd\n# convert list into a DataFrame\ndf = pd.DataFrame(french_predictions, columns=[\"Predicted French premises\"])\n\n \n\n# save the DataFrame to a CSV file\ndf.to_csv(\"predicted french sentences 2000.csv\", index=False)","metadata":{"execution":{"iopub.status.busy":"2023-08-03T23:16:50.213757Z","iopub.execute_input":"2023-08-03T23:16:50.214148Z","iopub.status.idle":"2023-08-03T23:16:50.242395Z","shell.execute_reply.started":"2023-08-03T23:16:50.214115Z","shell.execute_reply":"2023-08-03T23:16:50.241377Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"from nltk.translate.bleu_score import corpus_bleu\nreference_french_premises = french_test[1000:2000]\n\nprint(len(reference_french_premises))\nprint(len(french_predictions))\n# print('Ref sen', reference_french_premises)\n# print()\n# print('pred sen', french_predictions)\n\ntokenized_references = [[ref.split()] for ref in reference_french_premises]\ntokenized_candidates = [pred.split() for pred in french_predictions]\n\n# Print BLEU scores\nbleu_scores = {}\nbleu_scores['total'] = corpus_bleu(tokenized_references, tokenized_candidates)\nbleu_scores['1-grams'] = corpus_bleu(tokenized_references, tokenized_candidates, weights=(1.0, 0, 0, 0))\nbleu_scores['1-2-grams'] = corpus_bleu(tokenized_references, tokenized_candidates, weights=(0.5, 0.5, 0, 0))\nbleu_scores['1-3-grams'] = corpus_bleu(tokenized_references, tokenized_candidates, weights=(0.3, 0.3, 0.3, 0))\nbleu_scores['1-4-grams'] = corpus_bleu(tokenized_references, tokenized_candidates, weights=(0.25, 0.25, 0.25, 0.25))\nprint(\"BLEU Scores:\", bleu_scores)\n","metadata":{"execution":{"iopub.status.busy":"2023-08-03T23:17:21.059921Z","iopub.execute_input":"2023-08-03T23:17:21.060340Z","iopub.status.idle":"2023-08-03T23:17:23.673761Z","shell.execute_reply.started":"2023-08-03T23:17:21.060289Z","shell.execute_reply":"2023-08-03T23:17:23.672591Z"},"trusted":true},"execution_count":26,"outputs":[{"name":"stdout","text":"1000\n1000\nBLEU Scores: {'total': 0.4920510781708796, '1-grams': 0.6894850220491534, '1-2-grams': 0.6118434346957737, '1-3-grams': 0.579472540540536, '1-4-grams': 0.4920510781708796}\n","output_type":"stream"}]},{"cell_type":"code","source":"import matplotlib.pyplot as plt \nplt.bar(x = bleu_scores.keys(), height = bleu_scores.values())\nplt.title(\"BLEU Score with the testing set\")\nplt.ylim((0,1))\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-08-03T23:17:28.719637Z","iopub.execute_input":"2023-08-03T23:17:28.720087Z","iopub.status.idle":"2023-08-03T23:17:29.070242Z","shell.execute_reply.started":"2023-08-03T23:17:28.720047Z","shell.execute_reply":"2023-08-03T23:17:29.069137Z"},"trusted":true},"execution_count":27,"outputs":[{"output_type":"display_data","data":{"text/plain":"<Figure size 640x480 with 1 Axes>","image/png":"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"},"metadata":{}}]},{"cell_type":"code","source":"# import tensorflow as tf\n# from transformers import TFAutoModelForSeq2SeqLM, AutoTokenizer\n\n# # Load pre-trained model and tokenizer for translation\n# model_name = \"Helsinki-NLP/opus-mt-en-fr\"\n# tokenizer = AutoTokenizer.from_pretrained(model_name)\n# model = TFAutoModelForSeq2SeqLM.from_pretrained(model_name)\n\n# french_hypothesis = []\n\n# # English sentence to be translated\n# #english_sentence = \"Hello, how are you?\"\n\n# # Tokenize input sentence\n# for premise in english_hypothesis[:3]:\n#     # Tokenize input sentence\n#     inputs = tokenizer(premise, truncation=True, padding=True, return_tensors=\"tf\")\n\n#     # Perform translation\n#     outputs = model.generate(inputs[\"input_ids\"])\n#     french_ids = outputs[0].numpy()\n\n#     # Decode translated sentence\n#     french_sentence = tokenizer.decode(french_ids, skip_special_tokens=True)\n#     french_hypothesis.append(french_sentence)\n\n# # Print the translated sentences\n# print(\"English hypothesis:\", english_hypothesis[2])\n# print(\"French hypothesis:\", french_hypothesis[2])\n# print()","metadata":{"execution":{"iopub.status.busy":"2023-08-02T20:27:54.475936Z","iopub.status.idle":"2023-08-02T20:27:54.476741Z","shell.execute_reply.started":"2023-08-02T20:27:54.476479Z","shell.execute_reply":"2023-08-02T20:27:54.476502Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# #Splitting hypothesis\n# english_train_hyp, english_test_hyp, french_train_hyp, french_test_hyp = train_test_split(english_hypothesis, french_hypothesis_ref, test_size = 0.2, random_state = 42)","metadata":{"execution":{"iopub.status.busy":"2023-08-02T20:27:54.478039Z","iopub.status.idle":"2023-08-02T20:27:54.478844Z","shell.execute_reply.started":"2023-08-02T20:27:54.478599Z","shell.execute_reply":"2023-08-02T20:27:54.478623Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# #fine tuning hypothesis\n# from transformers import TFAutoModelForSeq2SeqLM, AutoTokenizer, AdamWeightDecay\n# import tensorflow as tf\n\n# model_name = \"Helsinki-NLP/opus-mt-en-fr\"\n# tokenizer = AutoTokenizer.from_pretrained(model_name)\n\n# # Tokenize inputs and outputs\n# inputs = tokenizer(english_train_hyp[:10000], truncation=True, padding=True, return_tensors=\"tf\")\n# outputs = tokenizer(french_train_hyp[:10000], truncation=True, padding=True, return_tensors=\"tf\")\n\n# # Create a function that will transform our dataset\n# def map_func(input_ids, masks, labels):\n#     return {'input_ids': input_ids, 'attention_mask': masks}, labels\n\n# # Create tf.data.Datasets\n# BATCH_SIZE = 16\n# tf_train_dataset = tf.data.Dataset.from_tensor_slices((inputs['input_ids'], inputs['attention_mask'], outputs['input_ids']))\n# tf_train_dataset = tf_train_dataset.map(map_func).shuffle(10000).batch(BATCH_SIZE)\n\n# tf_test_dataset = tf.data.Dataset.from_tensor_slices((inputs['input_ids'], inputs['attention_mask'], outputs['input_ids']))\n# tf_test_dataset = tf_test_dataset.map(map_func).batch(BATCH_SIZE)\n\n# optimizer = AdamWeightDecay(learning_rate=2e-5, weight_decay_rate=0.01)\n\n# model = TFAutoModelForSeq2SeqLM.from_pretrained(model_name)\n# model.compile(optimizer=optimizer)\n# model.fit(tf_train_dataset, validation_data=tf_test_dataset, epochs=3)\n","metadata":{"execution":{"iopub.status.busy":"2023-08-02T20:27:54.480172Z","iopub.status.idle":"2023-08-02T20:27:54.481028Z","shell.execute_reply.started":"2023-08-02T20:27:54.480783Z","shell.execute_reply":"2023-08-02T20:27:54.480805Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# save_directory = \"/kaggle/working\"  # Specify the directory to save the model\n\n# # Save the model and tokenizer\n# model.save_pretrained(save_directory)\n# tokenizer.save_pretrained(save_directory)\n\n# print(\"Model saved successfully.\")","metadata":{"execution":{"iopub.status.busy":"2023-08-02T20:27:54.482374Z","iopub.status.idle":"2023-08-02T20:27:54.483390Z","shell.execute_reply.started":"2023-08-02T20:27:54.483139Z","shell.execute_reply":"2023-08-02T20:27:54.483163Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# from transformers import TFAutoModelForSeq2SeqLM, AutoTokenizer, AdamWeightDecay\n# import tensorflow as tf\n\n# model_name = \"Helsinki-NLP/opus-mt-en-fr\"\n# tokenizer = AutoTokenizer.from_pretrained(model_name)\n\n# # Tokenize inputs and outputs\n# inputs = tokenizer(english_train[:10000], truncation=True, padding=True, return_tensors=\"tf\")\n# outputs = tokenizer(french_train[:10000], truncation=True, padding=True, return_tensors=\"tf\")\n\n# # Create a function that will transform our dataset\n# def map_func(input_ids, masks, labels):\n#     return {'input_ids': input_ids, 'attention_mask': masks}, labels\n\n# # Create tf.data.Datasets\n# BATCH_SIZE = 16\n# tf_train_dataset = tf.data.Dataset.from_tensor_slices((inputs['input_ids'], inputs['attention_mask'], outputs['input_ids']))\n# tf_train_dataset = tf_train_dataset.map(map_func).shuffle(10000).batch(BATCH_SIZE)\n\n# tf_test_dataset = tf.data.Dataset.from_tensor_slices((inputs['input_ids'], inputs['attention_mask'], outputs['input_ids']))\n# tf_test_dataset = tf_test_dataset.map(map_func).batch(BATCH_SIZE)\n\n# optimizer = AdamWeightDecay(learning_rate=2e-5, weight_decay_rate=0.01)\n\n# model = TFAutoModelForSeq2SeqLM.from_pretrained(model_name)\n# model.compile(optimizer=optimizer)\n# model.fit(tf_train_dataset, validation_data=tf_test_dataset, epochs=3)\n","metadata":{"execution":{"iopub.status.busy":"2023-08-02T20:27:54.484806Z","iopub.status.idle":"2023-08-02T20:27:54.485596Z","shell.execute_reply.started":"2023-08-02T20:27:54.485334Z","shell.execute_reply":"2023-08-02T20:27:54.485356Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# from nltk.translate.bleu_score import corpus_bleu\n# reference_french_premises = french_test[:2]\n\n# print(len(reference_french_premises))\n# print(len(french_predictions))\n# # print('Ref sen', reference_french_premises)\n# # print()\n# # print('pred sen', french_predictions)\n\n# tokenized_references = [[ref.split()] for ref in reference_french_premises]\n# tokenized_candidates = [pred.split() for pred in french_predictions]\n\n# # Print BLEU scores\n# bleu_scores = {}\n# bleu_scores['total'] = corpus_bleu(tokenized_references, tokenized_candidates)\n# bleu_scores['1-grams'] = corpus_bleu(tokenized_references, tokenized_candidates, weights=(1.0, 0, 0, 0))\n# bleu_scores['1-2-grams'] = corpus_bleu(tokenized_references, tokenized_candidates, weights=(0.5, 0.5, 0, 0))\n# bleu_scores['1-3-grams'] = corpus_bleu(tokenized_references, tokenized_candidates, weights=(0.3, 0.3, 0.3, 0))\n# bleu_scores['1-4-grams'] = corpus_bleu(tokenized_references, tokenized_candidates, weights=(0.25, 0.25, 0.25, 0.25))\n# print(\"BLEU Scores:\", bleu_scores)","metadata":{"execution":{"iopub.status.busy":"2023-08-02T20:27:54.487011Z","iopub.status.idle":"2023-08-02T20:27:54.487801Z","shell.execute_reply.started":"2023-08-02T20:27:54.487539Z","shell.execute_reply":"2023-08-02T20:27:54.487562Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# import tensorflow as tf\n# #from transformers import TFBertModel, BertTokenizer\n# from transformers import TFAutoModelForSeq2SeqLM, AutoTokenizer\n# from sklearn.model_selection import train_test_split\n# from tensorflow.keras.losses import SparseCategoricalCrossentropy\n# from tensorflow.keras.optimizers import Adam\n\n# #saved_directory = \"/kaggle/working\"  # Specify the directory where the model was saved\n\n# # model = TFBertModel.from_pretrained(saved_directory)\n# # tokenizer = BertTokenizer.from_pretrained(saved_directory)\n\n# model_name = \"Helsinki-NLP/opus-mt-en-fr\"\n# tokenizer = AutoTokenizer.from_pretrained(model_name)\n# model = TFAutoModelForSeq2SeqLM.from_pretrained(model_name)\n\n# french_predictions = []\n\n# # Function to predict French sentences\n# def predict_french_sentences(sentences):\n#     # Tokenize the input sentences\n#     tokenized_inputs = tokenizer(sentences, truncation=True, padding=True, return_tensors=\"tf\")\n\n#     # Generate predictions\n#     predicted_ids = model.generate(tokenized_inputs.input_ids)\n#     print(predicted_ids)\n#     predicted_sentences = tokenizer.batch_decode(predicted_ids, skip_special_tokens=True)\n\n#     return predicted_sentences\n\n# # Example usage\n# for i in range(10):\n#     english_sentence = english_hypothesis[5001 + i]\n#     predicted_french_sentence = predict_french_sentences(english_sentence)\n#     french_predictions.append(predicted_french_sentence[0])\n#     print(\"English sentence:\", english_sentence)\n#     print(\"Predicted French sentence:\", predicted_french_sentence[0])\n\n# # Print the predicted French sentence\n# # print(\"English sentence:\", english_sentence)\n# # print(\"Predicted French sentence:\", predicted_french_sentence)","metadata":{"execution":{"iopub.status.busy":"2023-08-02T20:27:54.489202Z","iopub.status.idle":"2023-08-02T20:27:54.490010Z","shell.execute_reply.started":"2023-08-02T20:27:54.489753Z","shell.execute_reply":"2023-08-02T20:27:54.489776Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# from nltk.translate.bleu_score import corpus_bleu\n# reference_french_premises = french_premises_ref[500:550]\n\n# print(len(reference_french_premises))\n# print(len(french_predictions))\n# # print('Ref sen', reference_french_premises)\n# # print()\n# # print('pred sen', french_predictions)\n\n# tokenized_references = [[ref.split()] for ref in reference_french_premises]\n# tokenized_candidates = [pred.split() for pred in french_predictions]\n\n# # Print BLEU scores\n# bleu_scores = {}\n# bleu_scores['total'] = corpus_bleu(tokenized_references, tokenized_candidates)\n# bleu_scores['1-grams'] = corpus_bleu(tokenized_references, tokenized_candidates, weights=(1.0, 0, 0, 0))\n# bleu_scores['1-2-grams'] = corpus_bleu(tokenized_references, tokenized_candidates, weights=(0.5, 0.5, 0, 0))\n# bleu_scores['1-3-grams'] = corpus_bleu(tokenized_references, tokenized_candidates, weights=(0.3, 0.3, 0.3, 0))\n# bleu_scores['1-4-grams'] = corpus_bleu(tokenized_references, tokenized_candidates, weights=(0.25, 0.25, 0.25, 0.25))\n# print(\"BLEU Scores:\", bleu_scores)","metadata":{"execution":{"iopub.status.busy":"2023-08-02T20:27:54.491410Z","iopub.status.idle":"2023-08-02T20:27:54.492205Z","shell.execute_reply.started":"2023-08-02T20:27:54.491960Z","shell.execute_reply":"2023-08-02T20:27:54.491984Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# import matplotlib.pyplot as plt \n# plt.bar(x = bleu_scores.keys(), height = bleu_scores.values())\n# plt.title(\"BLEU Score with the testing set\")\n# plt.ylim((0,1))\n# plt.show()","metadata":{"execution":{"iopub.status.busy":"2023-08-02T20:27:54.493677Z","iopub.status.idle":"2023-08-02T20:27:54.494506Z","shell.execute_reply.started":"2023-08-02T20:27:54.494237Z","shell.execute_reply":"2023-08-02T20:27:54.494261Z"},"trusted":true},"execution_count":null,"outputs":[]}]}